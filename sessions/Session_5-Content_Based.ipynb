{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae6011ca",
   "metadata": {},
   "source": [
    "# Content-based recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a455b8a",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "Based on the TF-IDF vectors obtained in the Exercise 2 from Session 4, represent each user in the same vector space. Amongst other feasible solutions, you can represent a user (user profile) by computing the weighted mean of the items vectors. Compute the cosine similarity for user 'A39WWMBA0299ZF' and all products in the training set not rated by the user. What are the top-5 recommended items for user 'A39WWMBA0299ZF'? Print out the top-5 items and their similarity score.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "159b93f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f357dcaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "      <th>advanc</th>\n",
       "      <th>aerosol</th>\n",
       "      <th>age</th>\n",
       "      <th>ageless</th>\n",
       "      <th>air</th>\n",
       "      <th>allergen</th>\n",
       "      <th>almond</th>\n",
       "      <th>american</th>\n",
       "      <th>andal</th>\n",
       "      <th>...</th>\n",
       "      <th>wintergreen</th>\n",
       "      <th>wiseway</th>\n",
       "      <th>witch</th>\n",
       "      <th>women</th>\n",
       "      <th>wood</th>\n",
       "      <th>work</th>\n",
       "      <th>wrinkl</th>\n",
       "      <th>yardley</th>\n",
       "      <th>youth</th>\n",
       "      <th>zum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asin</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B0000530HU</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00006L9LC</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00021DJ32</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B0002JHI1I</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.351338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B0006O10P4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.782655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B019LAI4HU</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B019V2KYZS</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B01BNEYGQU</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B01DKQAXC0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.227715</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B01E7UKR38</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 394 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            action  advanc  aerosol  age  ageless  air  allergen  almond  \\\n",
       "asin                                                                       \n",
       "B0000530HU     0.0     0.0      0.0  0.0      0.0  0.0       0.0     0.0   \n",
       "B00006L9LC     0.0     0.0      0.0  0.0      0.0  0.0       0.0     0.0   \n",
       "B00021DJ32     0.0     0.0      0.0  0.0      0.0  0.0       0.0     0.0   \n",
       "B0002JHI1I     0.0     0.0      0.0  0.0      0.0  0.0       0.0     0.0   \n",
       "B0006O10P4     0.0     0.0      0.0  0.0      0.0  0.0       0.0     0.0   \n",
       "...            ...     ...      ...  ...      ...  ...       ...     ...   \n",
       "B019LAI4HU     0.0     0.0      0.0  0.0      0.0  0.0       0.0     0.0   \n",
       "B019V2KYZS     0.0     0.0      0.0  0.0      0.0  0.0       0.0     0.0   \n",
       "B01BNEYGQU     0.0     0.0      0.0  0.0      0.0  0.0       0.0     0.0   \n",
       "B01DKQAXC0     0.0     0.0      0.0  0.0      0.0  0.0       0.0     0.0   \n",
       "B01E7UKR38     0.0     0.0      0.0  0.0      0.0  0.0       0.0     0.0   \n",
       "\n",
       "            american  andal  ...  wintergreen  wiseway  witch     women  wood  \\\n",
       "asin                         ...                                                \n",
       "B0000530HU       0.0    0.0  ...          0.0      0.0    0.0  0.000000   0.0   \n",
       "B00006L9LC       0.0    0.0  ...          0.0      0.0    0.0  0.000000   0.0   \n",
       "B00021DJ32       0.0    0.0  ...          0.0      0.0    0.0  0.000000   0.0   \n",
       "B0002JHI1I       0.0    0.0  ...          0.0      0.0    0.0  0.000000   0.0   \n",
       "B0006O10P4       0.0    0.0  ...          0.0      0.0    0.0  0.000000   0.0   \n",
       "...              ...    ...  ...          ...      ...    ...       ...   ...   \n",
       "B019LAI4HU       0.0    0.0  ...          0.0      0.0    0.0  0.000000   0.0   \n",
       "B019V2KYZS       0.0    0.0  ...          0.0      0.0    0.0  0.000000   0.0   \n",
       "B01BNEYGQU       0.0    0.0  ...          0.0      0.0    0.0  0.000000   0.0   \n",
       "B01DKQAXC0       0.0    0.0  ...          0.0      0.0    0.0  0.227715   0.0   \n",
       "B01E7UKR38       0.0    0.0  ...          0.0      0.0    0.0  0.000000   0.0   \n",
       "\n",
       "            work    wrinkl  yardley  youth       zum  \n",
       "asin                                                  \n",
       "B0000530HU   0.0  0.000000      0.0    0.0  0.000000  \n",
       "B00006L9LC   0.0  0.000000      0.0    0.0  0.000000  \n",
       "B00021DJ32   0.0  0.000000      0.0    0.0  0.000000  \n",
       "B0002JHI1I   0.0  0.351338      0.0    0.0  0.000000  \n",
       "B0006O10P4   0.0  0.000000      0.0    0.0  0.782655  \n",
       "...          ...       ...      ...    ...       ...  \n",
       "B019LAI4HU   0.0  0.000000      0.0    0.0  0.000000  \n",
       "B019V2KYZS   0.0  0.000000      0.0    0.0  0.000000  \n",
       "B01BNEYGQU   0.0  0.000000      0.0    0.0  0.000000  \n",
       "B01DKQAXC0   0.0  0.000000      0.0    0.0  0.000000  \n",
       "B01E7UKR38   0.0  0.000000      0.0    0.0  0.000000  \n",
       "\n",
       "[84 rows x 394 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf = pd.read_pickle(\"asin_tfidf.pkl\")\n",
    "\n",
    "df = pd.read_pickle(\"train.pkl\")\n",
    "df = df[[\"overall\", \"reviewerID\", \"asin\"]]\n",
    "\n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6c03801e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://stackoverflow.com/questions/31521027/groupby-weighted-average-and-sum-in-pandas-dataframe\n",
    "# def weighted_average(df,drop_cols,weight_col,by_col):\n",
    "#     df['_data_times_weight'] = df.drop(drop_cols,axis=1)*df[weight_col]\n",
    "#     df['_weight_where_notnull'] = df[weight_col]*pd.notnull(df.drop(drop_cols,axis=1))\n",
    "#     g = df.groupby(by_col)\n",
    "#     result = g['_data_times_weight'].sum() / g['_weight_where_notnull'].sum()\n",
    "#     del df['_data_times_weight'], df['_weight_where_notnull']\n",
    "#     return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8774abbe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "      <th>advanc</th>\n",
       "      <th>aerosol</th>\n",
       "      <th>age</th>\n",
       "      <th>ageless</th>\n",
       "      <th>air</th>\n",
       "      <th>allergen</th>\n",
       "      <th>almond</th>\n",
       "      <th>american</th>\n",
       "      <th>andal</th>\n",
       "      <th>...</th>\n",
       "      <th>wintergreen</th>\n",
       "      <th>wiseway</th>\n",
       "      <th>witch</th>\n",
       "      <th>women</th>\n",
       "      <th>wood</th>\n",
       "      <th>work</th>\n",
       "      <th>wrinkl</th>\n",
       "      <th>yardley</th>\n",
       "      <th>youth</th>\n",
       "      <th>zum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviewerID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A105A034ZG9EHO</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.015725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A10JB7YPWZGRF4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.455432</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.015725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A10M2MLE2R0L6K</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A10P0NAKKRYKTZ</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.455432</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A10ZJZNO4DAVB</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.455432</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZCOSCQG73JZ1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZD3ON9ZMEGL6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.015725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZFYUPGEE6KLW</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZJMUP77WBQZQ</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.455432</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZRD4IZU6TBFV</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.455432</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.015725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>981 rows × 394 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                action  advanc  aerosol  age  ageless  air  allergen  almond  \\\n",
       "reviewerID                                                                     \n",
       "A105A034ZG9EHO     0.0     0.0      0.0  0.0      0.0  0.0       0.0     0.0   \n",
       "A10JB7YPWZGRF4     0.0     0.0      0.0  0.0      0.0  0.0       0.0     0.0   \n",
       "A10M2MLE2R0L6K     0.0     0.0      0.0  0.0      0.0  0.0       0.0     0.0   \n",
       "A10P0NAKKRYKTZ     0.0     0.0      0.0  0.0      0.0  0.0       0.0     0.0   \n",
       "A10ZJZNO4DAVB      0.0     0.0      0.0  0.0      0.0  0.0       0.0     0.0   \n",
       "...                ...     ...      ...  ...      ...  ...       ...     ...   \n",
       "AZCOSCQG73JZ1      0.0     0.0      0.0  0.0      0.0  0.0       0.0     0.0   \n",
       "AZD3ON9ZMEGL6      0.0     0.0      0.0  0.0      0.0  0.0       0.0     0.0   \n",
       "AZFYUPGEE6KLW      0.0     0.0      0.0  0.0      0.0  0.0       0.0     0.0   \n",
       "AZJMUP77WBQZQ      0.0     0.0      0.0  0.0      0.0  0.0       0.0     0.0   \n",
       "AZRD4IZU6TBFV      0.0     0.0      0.0  0.0      0.0  0.0       0.0     0.0   \n",
       "\n",
       "                american  andal  ...  wintergreen  wiseway  witch  women  \\\n",
       "reviewerID                       ...                                       \n",
       "A105A034ZG9EHO       0.0    0.0  ...          0.0      0.0    0.0    0.0   \n",
       "A10JB7YPWZGRF4       0.0    0.0  ...          0.0      0.0    0.0    0.0   \n",
       "A10M2MLE2R0L6K       0.0    0.0  ...          0.0      0.0    0.0    0.0   \n",
       "A10P0NAKKRYKTZ       0.0    0.0  ...          0.0      0.0    0.0    0.0   \n",
       "A10ZJZNO4DAVB        0.0    0.0  ...          0.0      0.0    0.0    0.0   \n",
       "...                  ...    ...  ...          ...      ...    ...    ...   \n",
       "AZCOSCQG73JZ1        0.0    0.0  ...          0.0      0.0    0.0    0.0   \n",
       "AZD3ON9ZMEGL6        0.0    0.0  ...          0.0      0.0    0.0    0.0   \n",
       "AZFYUPGEE6KLW        0.0    0.0  ...          0.0      0.0    0.0    0.0   \n",
       "AZJMUP77WBQZQ        0.0    0.0  ...          0.0      0.0    0.0    0.0   \n",
       "AZRD4IZU6TBFV        0.0    0.0  ...          0.0      0.0    0.0    0.0   \n",
       "\n",
       "                wood      work  wrinkl   yardley  youth  zum  \n",
       "reviewerID                                                    \n",
       "A105A034ZG9EHO   0.0  0.000000     0.0  1.015725    0.0  0.0  \n",
       "A10JB7YPWZGRF4   0.0  0.455432     0.0  1.015725    0.0  0.0  \n",
       "A10M2MLE2R0L6K   0.0  0.000000     0.0  0.000000    0.0  0.0  \n",
       "A10P0NAKKRYKTZ   0.0  0.455432     0.0  0.000000    0.0  0.0  \n",
       "A10ZJZNO4DAVB    0.0  0.455432     0.0  0.000000    0.0  0.0  \n",
       "...              ...       ...     ...       ...    ...  ...  \n",
       "AZCOSCQG73JZ1    0.0  0.000000     0.0  0.000000    0.0  0.0  \n",
       "AZD3ON9ZMEGL6    0.0  0.000000     0.0  1.015725    0.0  0.0  \n",
       "AZFYUPGEE6KLW    0.0  0.000000     0.0  0.000000    0.0  0.0  \n",
       "AZJMUP77WBQZQ    0.0  0.455432     0.0  0.000000    0.0  0.0  \n",
       "AZRD4IZU6TBFV    0.0  0.455432     0.0  1.015725    0.0  0.0  \n",
       "\n",
       "[981 rows x 394 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full = df.merge(tf, on=\"asin\", how=\"left\").dropna()\n",
    "mask = ~full.columns.isin([\"overall\", \"reviewerID\", \"asin\"])\n",
    "full.loc[:, mask]  = full.loc[:, mask].mul(full[\"overall\"], axis=0)\n",
    "\n",
    "mask2 = ~full.columns.isin([\"overall\", \"asin\"])\n",
    "full = full.loc[:, mask2].groupby(\"reviewerID\").mean()\n",
    "full\n",
    "\n",
    "\n",
    "# wm = lambda x: np.average(x, weights=df.loc[x.index, \"overall\"])\n",
    "# full.drop(\"asin\",axis=1).groupby(\"reviewerID\").apply(lambda x: wm(x))\n",
    "# weighted_average(full, [\"asin\", \"overall\"], \"overall\", \"reviewerID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b7e7929b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asin\n",
       "B00EYZY6LQ    0.680414\n",
       "B001LNODUS    0.680414\n",
       "B019FWRG3C    0.427936\n",
       "B0010ZBORW    0.272166\n",
       "B00W259T7G    0.188967\n",
       "Name: sim, dtype: float64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "u = \"A39WWMBA0299ZF\"\n",
    "\n",
    "tff = tf.copy()\n",
    "tff[\"sim\"] =  cosine_similarity(tff, full[full.index == u])\n",
    "# tff.drop(\"asin\",axis=1) @ full[full.index == u].T / (np.linalg.norm(tff.drop(\"asin\",axis=1))*np.linalg.norm(full[full.index == u].T))\n",
    "tff[\"sim\"].nlargest(5)\n",
    "# 'B019FWRG3C', 0.419),\n",
    "# ('B00W259T7G', 0.206),\n",
    "# ('B00IJHY54S', 0.102),\n",
    "# ('B0006O10P4', 0.094),\n",
    "# ('B000LIBUBY', 0.083)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599f2bbe",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7805a3",
   "metadata": {},
   "source": [
    "Compute the systems’ hit rate based on the top-5, top-10 and top-20 recommendations, averaged over the total number of users. Remember that, as we are evaluating the system, you should compute the hit rate over the test set. How well/bad does this Content-based approach perform compared to the Collaborative Filtering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-dispatch",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.groupby(['uid']).apply(lambda x: x.nlargest(k,['est'])).reset_index(drop=True)[[\"uid\", \"iid\", \"est\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7455795",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relevant_column(preds, df_test, k): \n",
    "    topKpreds = preds.groupby(['uid']).apply(lambda x: x.nlargest(k,['est'])).reset_index(drop=True)[[\"uid\", \"iid\", \"est\"]]\n",
    "    merged = topKpreds.merge(df_test[[\"uid\", \"iid\", \"overall\"]], how=\"left\", on=[\"uid\", \"iid\"])\n",
    "    merged[\"relevant\"] = (merged[\"overall\"] >= 4) * 1 \n",
    "    return merged\n",
    "\n",
    "def HRatK(preds, df_test, k):\n",
    "    merged = relevant_column(preds, df_test, k)\n",
    "    score = merged[[\"uid\", \"iid\", \"relevant\"]].groupby(by=\"uid\")[\"relevant\"].apply(lambda x: x.any()*1).mean()\n",
    "    return score\n",
    "HRatK(nb, df_test, 5), HRatK(lf, df_test, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d74d43",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "\n",
    "Repeat Exercise 1 and 2, this time representing the products and users in a word2vec vector space. You may use the gensim library and download the 300-dimension embeddings from Google. Source: https://radimrehurek.com/gensim/models/word2vec.html#pretrained-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "amateur-accuracy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before dropping dups: 32892\n",
      "After: 32488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ayaya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ayaya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield json.loads(l)\n",
    "\n",
    "def getDF(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "\n",
    "train = pd.read_pickle(\"train.pkl\")\n",
    "test = pd.read_pickle(\"test.pkl\")\n",
    "\n",
    "train_file ='train.pkl'\n",
    "test_file = 'test.pkl'\n",
    "meta_file = 'meta_All_Beauty.json.gz'\n",
    "meta = getDF(meta_file)\n",
    "print(\"Before dropping dups:\", len(meta))\n",
    "meta = meta.drop_duplicates([\"asin\"], keep=\"last\")\n",
    "print(\"After:\", len(meta))\n",
    "\n",
    "allowed_asins = np.unique(np.array([*train.asin.to_list(), *test.asin.to_list()]))\n",
    "meta = meta[meta[\"asin\"].isin(allowed_asins)].reset_index(drop=True)\n",
    "\n",
    "len(allowed_asins), len(meta)\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "# https://stackoverflow.com/questions/45670532/stemming-words-with-nltk-python \n",
    "\n",
    "\n",
    "def cleanWords(x, stemmer=PorterStemmer()):\n",
    "    txt = BeautifulSoup(x).get_text()              #remove html\n",
    "    letters = re.sub(\"[^a-z]\", \" \", txt.lower())   #lowercase and only letters\n",
    "    words   = word_tokenize(letters)               #tokenize\n",
    "    stops = set(stopwords.words(\"english\"))        #define stopwords \n",
    "    meaningful_words = [w for w in words if not w in stops] \n",
    "\n",
    "    return ' '.join([stemmer.stem(w) for w in meaningful_words]) #combine\n",
    "\n",
    "df = meta.copy()\n",
    "df[\"words\"] = df[\"title\"].apply(lambda x: cleanWords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "religious-inclusion",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ayaya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-optimization",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_vectorizer.fit(df[\"words\"])\n",
    "tfidf = tfidf_vectorizer.fit_transform(df[\"words\"])\n",
    "names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "df2 = pd.DataFrame(arr, index=df[\"asin\"], columns=names)\n",
    "df2.to_pickle(\"asin_tfidf.pkl\")\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ca33a843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader\n",
    "# https://towardsdatascience.com/text-classification-with-nlp-tf-idf-vs-word2vec-vs-bert-41ff868d1794\n",
    "word2vec_vectors = gensim.downloader.load('word2vec-google-news-300')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "limited-interim",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                aqua velva shave classic ice blue ounc\n",
       "1                citr shine moistur burst shampoo fl oz\n",
       "2                                   nar blush taj mahal\n",
       "3        avalon organ wrinkl therapi coq cleans milk oz\n",
       "4                          zum zum bar anis lavend ounc\n",
       "                            ...                        \n",
       "79                     ultim bodi lotion michael kor oz\n",
       "80                     dolc gabbana compact parfum ounc\n",
       "81    colgat kid maximum caviti protect pump toothpa...\n",
       "82    bali secret natur deodor organ vegan women men...\n",
       "83                          essi gel coutur nail polish\n",
       "Name: words, Length: 84, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"words\"]#.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "abandoned-trading",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'velva' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-fc89582ebd48>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mword2vec_vectors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"words\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\ayaya\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key_or_keys)\u001b[0m\n\u001b[0;32m    395\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 397\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkey_or_keys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ayaya\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    395\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 397\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkey_or_keys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ayaya\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[1;34m(self, key, norm)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \"\"\"\n\u001b[1;32m--> 438\u001b[1;33m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill_norms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ayaya\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mget_index\u001b[1;34m(self, key, default)\u001b[0m\n\u001b[0;32m    410\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 412\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Key '{key}' not present\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Key 'velva' not present\""
     ]
    }
   ],
   "source": [
    "word2vec_vectors[df[\"words\"][0].split(\" \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "desperate-victory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05419922,  0.01708984, -0.00527954,  0.33203125, -0.25      ,\n",
       "       -0.01397705, -0.15039062, -0.265625  ,  0.01647949,  0.3828125 ,\n",
       "       -0.03295898, -0.09716797, -0.16308594, -0.04443359,  0.00946045,\n",
       "        0.18457031,  0.03637695,  0.16601562,  0.36328125, -0.25585938,\n",
       "        0.375     ,  0.171875  ,  0.21386719, -0.19921875,  0.13085938,\n",
       "       -0.07275391, -0.02819824,  0.11621094,  0.15332031,  0.09082031,\n",
       "        0.06787109, -0.0300293 , -0.16894531, -0.20800781, -0.03710938,\n",
       "       -0.22753906,  0.26367188,  0.012146  ,  0.18359375,  0.31054688,\n",
       "       -0.10791016, -0.19140625,  0.21582031,  0.13183594, -0.03515625,\n",
       "        0.18554688, -0.30859375,  0.04785156, -0.10986328,  0.14355469,\n",
       "       -0.43554688, -0.0378418 ,  0.10839844,  0.140625  , -0.10595703,\n",
       "        0.26171875, -0.17089844,  0.39453125,  0.12597656, -0.27734375,\n",
       "       -0.28125   ,  0.14746094, -0.20996094,  0.02355957,  0.18457031,\n",
       "        0.00445557, -0.27929688, -0.03637695, -0.29296875,  0.19628906,\n",
       "        0.20703125,  0.2890625 , -0.20507812,  0.06787109, -0.43164062,\n",
       "       -0.10986328, -0.2578125 , -0.02331543,  0.11328125,  0.23144531,\n",
       "       -0.04418945,  0.10839844, -0.2890625 , -0.09521484, -0.10351562,\n",
       "       -0.0324707 ,  0.07763672, -0.13378906,  0.22949219,  0.06298828,\n",
       "        0.08349609,  0.02929688, -0.11474609,  0.00534058, -0.12988281,\n",
       "        0.02514648,  0.08789062,  0.24511719, -0.11474609, -0.296875  ,\n",
       "       -0.59375   , -0.29492188, -0.13378906,  0.27734375, -0.04174805,\n",
       "        0.11621094,  0.28320312,  0.00241089,  0.13867188, -0.00683594,\n",
       "       -0.30078125,  0.16210938,  0.01171875, -0.13867188,  0.48828125,\n",
       "        0.02880859,  0.02416992,  0.04736328,  0.05859375, -0.23828125,\n",
       "        0.02758789,  0.05981445, -0.03857422,  0.06933594,  0.14941406,\n",
       "       -0.10888672, -0.07324219,  0.08789062,  0.27148438,  0.06591797,\n",
       "       -0.37890625, -0.26171875, -0.13183594,  0.09570312, -0.3125    ,\n",
       "        0.10205078,  0.03063965,  0.23632812,  0.00582886,  0.27734375,\n",
       "        0.20507812, -0.17871094, -0.31445312, -0.01586914,  0.13964844,\n",
       "        0.13574219,  0.0390625 , -0.29296875,  0.234375  , -0.33984375,\n",
       "       -0.11816406,  0.10644531, -0.18457031, -0.02099609,  0.02563477,\n",
       "        0.25390625,  0.07275391,  0.13574219, -0.00138092, -0.2578125 ,\n",
       "       -0.2890625 ,  0.10107422,  0.19238281, -0.04882812,  0.27929688,\n",
       "       -0.3359375 , -0.07373047,  0.01879883, -0.10986328, -0.04614258,\n",
       "        0.15722656,  0.06689453, -0.03417969,  0.16308594,  0.08642578,\n",
       "        0.44726562,  0.02026367, -0.01977539,  0.07958984,  0.17773438,\n",
       "       -0.04370117, -0.00952148,  0.16503906,  0.17285156,  0.23144531,\n",
       "       -0.04272461,  0.02355957,  0.18359375, -0.41601562, -0.01745605,\n",
       "        0.16796875,  0.04736328,  0.14257812,  0.08496094,  0.33984375,\n",
       "        0.1484375 , -0.34375   , -0.14160156, -0.06835938, -0.14648438,\n",
       "       -0.02844238,  0.07421875, -0.07666016,  0.12695312,  0.05859375,\n",
       "       -0.07568359, -0.03344727,  0.23632812, -0.16308594,  0.16503906,\n",
       "        0.1484375 , -0.2421875 , -0.3515625 , -0.30664062,  0.00491333,\n",
       "        0.17675781,  0.46289062,  0.14257812, -0.25      , -0.25976562,\n",
       "        0.04370117,  0.34960938,  0.05957031,  0.07617188, -0.02868652,\n",
       "       -0.09667969, -0.01281738,  0.05859375, -0.22949219, -0.1953125 ,\n",
       "       -0.12207031,  0.20117188, -0.42382812,  0.06005859,  0.50390625,\n",
       "        0.20898438,  0.11230469, -0.06054688,  0.33203125,  0.07421875,\n",
       "       -0.05786133,  0.11083984, -0.06494141,  0.05639648,  0.01757812,\n",
       "        0.08398438,  0.13769531,  0.2578125 ,  0.16796875, -0.16894531,\n",
       "        0.01794434,  0.16015625,  0.26171875,  0.31640625, -0.24804688,\n",
       "        0.05371094, -0.0859375 ,  0.17089844, -0.39453125, -0.00156403,\n",
       "       -0.07324219, -0.04614258, -0.16210938, -0.15722656,  0.21289062,\n",
       "       -0.15820312,  0.04394531,  0.28515625,  0.01196289, -0.26953125,\n",
       "       -0.04370117,  0.37109375,  0.04663086, -0.19726562,  0.3046875 ,\n",
       "       -0.36523438, -0.23632812,  0.08056641, -0.04248047, -0.14648438,\n",
       "       -0.06225586, -0.0534668 , -0.05664062,  0.18945312,  0.37109375,\n",
       "       -0.22070312,  0.04638672,  0.02612305, -0.11474609,  0.265625  ,\n",
       "       -0.02453613,  0.11083984, -0.02514648, -0.12060547,  0.05297852,\n",
       "        0.07128906,  0.00063705, -0.36523438, -0.13769531, -0.12890625],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def apply_word2vec(x):\n",
    "    res = 0 \n",
    "    for elm in x:\n",
    "        res += elm \n",
    "    return res/len(x)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
